{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3k2f 60 C High Pressure\n",
    "\n",
    "We are repeating the measurement of the 3k2f PPG polyol at 60 C to extend our data set to higher pressure in search of interesting supercritical behaviors. Along the way we will repeat a few data points at lower pressures to assess the repeatability of measurements. The experiment was performed with manual pressure changes and used DataThief on the plot generated by the Belsorp BG software to extra gravimetry data. \n",
    "\n",
    "The polyol is difunctional with molecular weight ~2700 g/mol in an atmosphere of carbon dioxide. The experiment was performed in the lab of Prof. Ernesto Di Maio in the Department of Chemical Engineering, Materials, and Industrial Production (DICMaPI) at the University of Naples Federico II from July 15-24, 2019.\n",
    "    \n",
    "The analysis computes the **solubility, interfacial tension, and specific volume** of the sample at pressures from 0 to 80 bar at 60 C. No diffusivity data are provided because of the lack of reliable time-series data at either the beginning or the end of the sorption curve due to large fluctuations in temperature (which have a magnified effect at higher pressure).\n",
    "\n",
    "We begin by importing the required Python libraries and setting parameters for this particular analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'date_str' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-1c62685bfadf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;31m# identify pressure step as a reference point in time to synchronize different runs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m     \u001b[0mt_shift\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataproc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_t_shift\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_p_interp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp_interp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdate_ref\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;31m# synchronize times of all measurements using only times that overlap\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - California Institute of Technology\\Documents\\Research\\Kornfield\\ANALYSIS\\g-adsa\\dataproc.py\u001b[0m in \u001b[0;36mcompute_t_shift\u001b[1;34m(metadata, i, t_p_interp, p_interp, p_file, date_ref, time_ref, dpdt_thresh, plot_pressure)\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m         \u001b[0mtime_dp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'time dp start'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 336\u001b[1;33m     \u001b[0mtime_date_ref\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTimeDate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdate_str\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdate_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime_str\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtime_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    337\u001b[0m     \u001b[0mtime_date_dp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTimeDate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdate_str\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdate_dp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime_str\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtime_dp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m     \u001b[0mt_since_ref\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTimeDate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiff_min\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime_date_ref\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime_date_dp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'date_str' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import glob\n",
    "import os\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "import dataproc\n",
    "from timedate import TimeDate\n",
    "\n",
    "from importlib import reload\n",
    "reload(dataproc)\n",
    "\n",
    "file_template = '201907*_*_*kPa*'\n",
    "metadata_file = '20190715_0724_3k2f_60c_hip_metadata.txt'\n",
    "# folder for gravimetry data from DataThief analysis of Belsorp BG data plotted from Rubotherm\n",
    "datathief_folder = '../../EXPERIMENTS/Italy/data/datathief/20190715_0724_3k2f_60c_hip/'\n",
    "grav_folder = '../../EXPERIMENTS/Italy/data/gravimetry/'\n",
    "date_ref = '7/15/2019'\n",
    "time_ref = '12:00:00'\n",
    "# system parameters\n",
    "polyol = '3k2f'\n",
    "T = 60\n",
    "i_50kPa = 0\n",
    "\n",
    "p_filepath_template = os.path.join(datathief_folder + file_template + '_p.txt')\n",
    "p_file_list = glob.glob(p_filepath_template)\n",
    "T_filepath_template = os.path.join(datathief_folder + file_template + '_T.txt')\n",
    "T_file_list = glob.glob(T_filepath_template)\n",
    "mp1_filepath_template = os.path.join(datathief_folder + file_template + '_mp1.txt')\n",
    "mp1_file_list = glob.glob(mp1_filepath_template)\n",
    "\n",
    "# initialize numpy arrays to store measured values (time,pressure, temperature, and MP1 balance reading)\n",
    "t_grav = []\n",
    "p_list = []\n",
    "T_list = []\n",
    "br_list = []\n",
    "bp_list = []\n",
    "time_list = []\n",
    "date_list = []\n",
    "# load metadata\n",
    "metadata = pd.read_csv(datathief_folder + metadata_file, header=0)\n",
    "\n",
    "# create reference date and time object\n",
    "time_date_ref = TimeDate(date_str=date_ref, time_str=time_ref)\n",
    "# load data from each file\n",
    "for i in range(len(p_file_list)):\n",
    "    # extract filepaths for pressure, temperature, and MP1 balance reading\n",
    "    p_file = p_file_list[i]\n",
    "    T_file = T_file_list[i]\n",
    "    mp1_file = mp1_file_list[i]\n",
    "    # load data\n",
    "    t_p, p = dataproc.load_datathief_data(p_file)\n",
    "    t_T, T_ = dataproc.load_datathief_data(T_file)\n",
    "    t_mp1, mp1 = dataproc.load_datathief_data(mp1_file)\n",
    "    # remove repeats and interpolate values so spacing is even\n",
    "    t_p_interp, p_interp = dataproc.interp(t_p, p, dt=2)\n",
    "    t_T_interp, T_interp = dataproc.interp(t_T, T_, dt=2)\n",
    "    t_mp1_interp, mp1_interp = dataproc.interp(t_mp1, mp1, dt=2)\n",
    "       \n",
    "    # identify pressure step as a reference point in time to synchronize different runs\n",
    "    t_shift = dataproc.compute_t_shift(metadata, i, t_p_interp, p_interp, p_file, date_ref, time_ref)\n",
    "        \n",
    "    # synchronize times of all measurements using only times that overlap\n",
    "    t_min = np.max([np.min(t_p), np.min(t_T), np.min(t_mp1)])\n",
    "    t_max = np.min([np.max(t_p), np.max(t_T), np.max(t_mp1)])\n",
    "    # remove repeats and interpolate values so spacing is even (all interpolated times should be the same)\n",
    "    t_p_interp, p_interp = dataproc.interp(t_p, p, dt=2, t_min=t_min, t_max=t_max)\n",
    "    t_T_interp, T_interp = dataproc.interp(t_T, T_, dt=2, t_min=t_min, t_max=t_max)\n",
    "    t_mp1_interp, mp1_interp = dataproc.interp(t_mp1, mp1, dt=2, t_min=t_min, t_max=t_max)\n",
    "    \n",
    "    # shift time\n",
    "    t_p_interp += t_shift\n",
    "    \n",
    "    # concatenate data\n",
    "    zero_last = i != i_50kPa # accidentally took zero measurement first for 50 kPa\n",
    "    dataproc.concatenate_data(metadata, i, date_ref, time_ref, time_list, date_list, \n",
    "                     t_grav, t_p_interp, p_interp, p_list, T_interp, T_list, \n",
    "                     mp1_interp, br_list, bp_list, zero_last=zero_last)\n",
    "    \n",
    "# save results in TRD file format\n",
    "df_trd = pd.DataFrame(columns=['DATE', 'TIME', 'Julabo_Ext_PV', 'WEITGHT(g)', 'BALANCE POSITION', 'Now Pressure(kPa)'])\n",
    "df_trd['DATE'] = date_list\n",
    "df_trd['TIME'] = time_list\n",
    "df_trd['Julabo_Ext_PV'] = T_list\n",
    "df_trd['WEITGHT(g)'] = br_list\n",
    "df_trd['BALANCE POSITION'] = bp_list\n",
    "df_trd['Now Pressure(kPa)'] = p_list\n",
    "trd_save_hdr = grav_folder + '%s_%dc-TRD-071519-1200' % (polyol, T)\n",
    "\n",
    "# save csv file with TRD header\n",
    "dataproc.save_trd(df_trd, trd_save_hdr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having created an artificial TRD file in the format that would have been produced by the Belsorp program during an automatic test, we can now proceed through the analysis as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import errprop\n",
    "import plot\n",
    "\n",
    "reload(dataproc)\n",
    "reload(errprop)\n",
    "\n",
    "\n",
    "# SET PARAMETERS\n",
    "# folder for ADSA data\n",
    "adsa_folder = '../../EXPERIMENTS/Italy/data/adsa/20190715_0724_3k2f_hip/'\n",
    "# list of data files with pendant drop volume (only) for ADSA generated from videos of a pendant drop\n",
    "adsa_volume_file_list = ['20190716_0717_3k2f_60c_hip_adsa_volume.csv', '20190718_0719_3k2f_60c_hip_adsa_volume.csv',\n",
    "                        '20190719_3k2f_60c_hip_adsa_volume.csv', '20190719_0720_3k2f_60c_hip_adsa_volume.csv',\n",
    "                        '20190722_3k2f_60c_hip_adsa_volume.csv', '20190722_0723_3k2f_60c_hip_adsa_volume.csv',\n",
    "                        '20190723_0724_3k2f_60c_hip_adsa_volume.csv']\n",
    "# list of data files with interfacial tension data--leave blank if not complete\n",
    "adsa_if_tension_file_list = []\n",
    "# filepath to gravimetry data \n",
    "grav_filepath = trd_save_hdr + '.csv'\n",
    "# file path to save results\n",
    "save_folder = '../g-adsa_results/'\n",
    "save_data_name = '3k2f_60c_hip.csv'\n",
    "save_plots = True\n",
    "# list of starting times of ADSA data relative to start of gravimetry data\n",
    "# gravimetry 7/15 13:04; adsa videos: 14:27, 7/16; 19:18, 7/17; 14:14, 7/18; 9:16, 7/19; 16:48, 7/19\n",
    "adsa_time_list = ['14:27:00', '19:18:00', '14:14:00', '9:16:00', '16:48:00', '10:02:00', '18:15:00', '16:02:00', '15:35:00']\n",
    "adsa_date_list = ['7/16/2019', '7/17/2019', '7/18/2019', '7/19/2019', '7/19/2019', '7/22/2019', '7/22/2019', \n",
    "                  '7/23/2019', '7/24/2019']\n",
    "# number of measurements to average for surface tension and volume readings\n",
    "n_adsa = 50\n",
    "\n",
    "# polyol code name\n",
    "polyol = '3k2f_hip_old'\n",
    "# weight of sample in atmospheric pressure, measured with analytical balance on 7/5/19 [g]\n",
    "w_samp_atm = 1.1153\n",
    "# volume of drop in atmospheric pressure, from 20190716_3k2f_60c_atm_snapshot.mdb [uL]\n",
    "v_drop_atm = 4.136\n",
    "# volume of drop under vacuum, from 20190716_3k2f_60c_0bar_snapshot.mdb [uL]\n",
    "v_drop_0 = 4.116\n",
    "# density of polyol sample from Dow technical data sheet at atmospheric pressure and 25 C (TDS)\n",
    "# and extrapolated using P-1000 Dow data [g/mL]\n",
    "rho_samp_atm = 0.977\n",
    "# volume of hook and crucible as measured in helium [mL]\n",
    "v_ref_he = 2.2674 # extrapolated from measurement by Maria Rosaria Di Caprio @ 25 C [mL]\n",
    "diam_cruc = 1.82 # diameter of crucible [cm]\n",
    "br_cruc = 7.2788 - 0.0003 # balance reading of crucible without polymer at atmospheric pressure [g]\n",
    "# measurements made manually with Rubotherm on 7/16/19 at 60 C\n",
    "mp1_atm = 14.02994\n",
    "zero_atm = 5.63404\n",
    "# ordered list of pressure set points (within p_thresh_frac of true values) [kPa]\n",
    "p_set_arr = metadata['p set [kPa]'].to_numpy(dtype=float)\n",
    "p_set_arr[0] = 45\n",
    "p_set_arr[1] = 1330\n",
    "p_thresh_frac = 0.04 # threshold for acceptable difference between actual pressure and set pressure [fraction]\n",
    "# resolution o pressure measurement [kPa]\n",
    "p_resolution = 1\n",
    "# number of measurements of pressure within equilibrium (2 min per measurement --> 30 minutes, 2-3 cycles of temperature,\n",
    "# which fluctuated every 10-15 minutes.)\n",
    "n_p_eq = 15\n",
    "\n",
    "# CONSTANTS\n",
    "# Set-point temperature [C]\n",
    "T = 60\n",
    "# atmospheric pressure [kPa]\n",
    "P_ATM = 101.3\n",
    "# mass of crucible and hooks measured June 26 with Rubotherm in atmosphere [g]\n",
    "TARE = 7.2788 - 0.0003 + dataproc.rho_co2(P_ATM, T)*v_ref_he \n",
    "\n",
    "# NOTE: PARAMETERS FOR ERROR PROPAGATION ARE DECLARED IN THE \"ERROR PROPAGATION\" SECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first compute the time delay from the reference time of the experiment (roughly the beginning) to the beginning of each ADSA measurement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initialize list of time delays until the start of the ADSA measurements\n",
    "adsa_t0_list = []\n",
    "# use TimeDate class to compute seconds of delay between the times and dates provided\n",
    "for i in range(len(adsa_time_list)):\n",
    "    adsa_time = adsa_time_list[i]\n",
    "    adsa_date = adsa_date_list[i]\n",
    "    adsa_td = TimeDate()\n",
    "    adsa_td.load_string(adsa_date, adsa_time)\n",
    "    # compute seconds after reference time that ADSA was started\n",
    "    adsa_t0_list += [TimeDate.diff_min(time_date_ref, adsa_td)*60]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Raw Data\n",
    "\n",
    "Next we load the raw data from gravimetry and ADSA that we wish to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load (and validate) raw data\n",
    "df, br_arr, bp_arr, p_arr, _, v_drop, t_adsa = dataproc.load_raw_data(adsa_folder, adsa_volume_file_list, \n",
    "                                                                      adsa_t0_list, grav_filepath, p_set_arr, zero_t_grav=False)\n",
    "t_adsa /= 60\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synchronize Gravimetry and ADSA Measurements\n",
    "\n",
    "In the next section, we synchronize gravimetry and ADSA measurements and identify their corresponding pressures. We then average the final values of the measurements of mass, tare, and interfacial tension (and take the standard deviation as an estimate of the error) and save them for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reload(dataproc)\n",
    "# Identify boundaries of pressure intervals and store gravimetry and ADSA data together after synchronization\n",
    "# initalize marker for pressure bounds\n",
    "i_p1 = 0\n",
    "focus_on_step = False\n",
    "select_index = 10\n",
    "plot_p = True\n",
    "# extract interfacial tension, drop volume, and mass at MP1 for each pressure\n",
    "for i in range(len(p_set_arr)):\n",
    "    p_set = p_set_arr[i]\n",
    "    print('Pressure = %d kPa.' % p_set)\n",
    "    if p_set == np.max(p_set_arr):\n",
    "        window_reduction = 0.01\n",
    "        print(p_set)\n",
    "        print(window_reduction)\n",
    "    else:\n",
    "        window_reduction = 0.25\n",
    "    # get indices of each measurement with pressure within thresholds--I checked and it finds the end within 2 or 3 pts.\n",
    "    i_p0, i_p1 = dataproc.get_curr_p_interval(p_arr, p_set, p_thresh_frac, last_bound=i_p1, window_reduction=window_reduction)\n",
    "    # take mean and standard deviation of final pressure near equilibrium\n",
    "    p_eq = p_arr[max(i_p0, i_p1-n_p_eq):i_p1]\n",
    "    df['p actual [kPa]'].iloc[i] = np.mean(p_eq)\n",
    "    df['p std [kPa]'].iloc[i] = max(np.std(p_eq), p_resolution)\n",
    "\n",
    "    if focus_on_step:\n",
    "        i_p -= 20\n",
    "        \n",
    "        if i != select_index:\n",
    "            continue\n",
    "    if plot_p:\n",
    "        # PLOT PRESSURE TO DEBUG IDENTIFICATION OF PRESSURE STEPS\n",
    "        plot.plot_line(t_grav[i_p0:i_p1], p_arr[i_p0:i_p1], xlabel='time [s]', ylabel='pressure [kPa]',\n",
    "                 title='Pressure at set point {0} kPa'.format(p_set))\n",
    "        if focus_on_step:\n",
    "            ax.set_xlim([220000, 250000])\n",
    "            ax.set_ylim([4800, 4950])\n",
    "\n",
    "    # store results in data frame\n",
    "    df = dataproc.store_grav_adsa_manual(df, metadata, i, i_p0, i_p1, t_grav, t_adsa, br_arr, bp_arr, v_drop, n_adsa, n_p_eq)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the volume measurements seem inaccurate, I will test by examining what should be the correct volume measurements for individual pressures. I start with 45 kPa (50 kPa)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# measurement at 45 kPa taken from 14:34 7/16 to 18:18 7/17\n",
    "# take measurements of volume from 16:00-18:00 7/17\n",
    "# how many minutes is that after the reference time?\n",
    "td_45_start = TimeDate()\n",
    "td_45_start.load_string('7/17/2019', '16:00:00')\n",
    "delay_45 = TimeDate.diff_min(time_date_ref, td_45_start)\n",
    "print(delay_45)\n",
    "\n",
    "# how many minutes into 20190716_0717_...adsa_volume is this?\n",
    "td_adsa_45 = TimeDate()\n",
    "td_adsa_45.load_string(adsa_date_list[0], adsa_time_list[0])\n",
    "delay_adsa_45 = TimeDate.diff_min(td_adsa_45, td_45_start)\n",
    "print(delay_adsa_45*60)\n",
    "print('seconds after start of 20190716_0717....csv')\n",
    "# this includes entries 158-170, which have an average of 4.42 uL, which is way above the \n",
    "# value computed by the program (around 4.1-4.2 uL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "Next we perform the analysis of the gravimetry and ADSA data to compute the solubility, diffusivity, interfacial tension, and specific volume. We begin with the solubility.\n",
    "\n",
    "#### Estimation of Polymer Mass and Volume under Vacuum\n",
    "\n",
    "Before estimating the solubility, I must compute the mass and volume of the polymer under vacuum. Since I did not take a measurement with the balance under vacuum, I will extrapolate the balance reading using measurements made at atmospheric pressure and 50 kPa, assuming a linear change in the balance reading at such low pressures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balance readings at equilibrium \n",
    "br_eq = df['mp1 [g]'].to_numpy(dtype=float) - df['zero [g]'].to_numpy(dtype=float)\n",
    "# balance reading at atmospheric pressure made before starting the tests\n",
    "br_eq_atm = mp1_atm - zero_atm\n",
    "# (extract value at 50 kPa) [g]\n",
    "br_eq_50kPa = br_eq[0]\n",
    "# extrapolate balance reading at 0 kPa assuming Henry's Law [g]\n",
    "br_eq_0 = br_eq_50kPa - 50*(br_eq_atm - br_eq_50kPa)/(P_ATM - 50)\n",
    "# balance reading for the mass of dissolved gas (must be corrected by buoyancy) [g]\n",
    "br_gas = br_eq - br_eq_0\n",
    "df['dissolved gas balance reading [g]'] = br_gas\n",
    "\n",
    "# volume of sample under atmospheric pressure\n",
    "v_samp_atm = w_samp_atm / rho_samp_atm\n",
    "# APPROXIMATE weight of gas at atmosphere by subtracting extrapolated balance reading at 0 kPa\n",
    "w_gas_atm = (br_eq_atm - br_eq_0) + dataproc.rho_co2(P_ATM, T)*(v_samp_atm + v_ref_he)\n",
    "# APPROXIMATE weight of polymer by subtracting approximated weight of gas from weight of sample at atmosphere\n",
    "w_poly_ad_hoc = w_samp_atm - w_gas_atm\n",
    "print('Dry polymer mass from ad hoc extrap = %3f g vs. mass of polymer at atmospheric pressure = %3f g.' % \\\n",
    "      (w_poly_ad_hoc, w_samp_atm))\n",
    "\n",
    "# compare result to that obtained by using tare measurement of crucible and hook\n",
    "w_poly = br_eq_0 - TARE\n",
    "print(\"Dry polymer mass estimated using tare measurement = \" + str(w_poly) + ' g.')\n",
    "# Volume of sample under vacuum (\"dry\" polyol) by extrapolating from the volume at 0 pressure\n",
    "v_poly = v_drop_0 / v_drop_atm * v_samp_atm\n",
    "print('Volume of dry polymer in crucible is approximately ~ %3f mL (using atmospheric density).' % v_poly)\n",
    "\n",
    "############################################################################################################\n",
    "# because the mass estimated using the tare measurement is greater than the atmospheric mass weighed with the\n",
    "# analytical balance, we will use the ad hoc expression in this case\n",
    "w_poly = w_poly_ad_hoc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Volume and Sample Volume\n",
    "\n",
    "Below we plot the measurements of the drop volume and use them to estimate the sample volume (we assume the drop volume increases by the same amount as the sample volume)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(plot)\n",
    "# Drop volume [uL]\n",
    "v_drop_eq = df['drop volume [uL]'].to_numpy(dtype=float)\n",
    "# Use fractional change in drop volume from atmospheric pressure to estimate sample volume\n",
    "v_samp = v_drop_eq / v_drop_atm * v_samp_atm\n",
    "df['sample volume [mL]'] = v_samp\n",
    "\n",
    "# extract data to plot\n",
    "p_plot = df['p actual [kPa]'].to_numpy(dtype=float)\n",
    "s_drop_vol = df['drop volume std [uL]'].to_numpy(dtype=float)\n",
    "# plot equilibrium drop volume vs. p (blue color for cool temperature data)\n",
    "ax = plot.plot_errorbars_ads_des(p_plot, v_drop_eq, s_drop_vol, p_set_arr, T, color='b', xlabel='p [kPa]', \n",
    "                                 ylabel='drop volume [uL]', title='Drop Volume vs. Pressure, %s %d C' % (polyol, T))\n",
    "\n",
    "if save_plots:\n",
    "    plt.savefig(save_folder + 'drop_vol_%s_%dc.pdf' % (polyol, T), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.interpolate import interp1d\n",
    "\n",
    "# # initialize arrays for data\n",
    "# t_grav = np.array([])\n",
    "# p_arr = np.array([])\n",
    "# T_arr = np.array([])\n",
    "# # br_arr = np.array([])\n",
    "# bp_arr = np.array([])\n",
    "\n",
    "# # load and store gravimetry data obtained using DataThief from the graphs in the Belsorp BG program\n",
    "# for i in range(len(grav_file_hdr_list)):\n",
    "#     grav_file_hdr = grav_file_hdr_list[i]\n",
    "#     p_data = np.genfromtxt(grav_folder + grav_file_hdr + '_p.txt', delimiter=',')\n",
    "#     t_p  = p_data[:, 0]\n",
    "#     p = p_data[:, 1]\n",
    "#     T_data = np.genfromtxt(grav_folder + grav_file_hdr + '_T.txt', delimiter=',')\n",
    "#     t_T  = T_data[:, 0]\n",
    "#     T = T_data[:, 1]\n",
    "#     mp1_data = np.genfromtxt(grav_folder + grav_file_hdr + '_mp1.txt', delimiter=',')\n",
    "#     t_mp1  = mp1_data[:, 0]\n",
    "#     mp1 = mp1_data[:, 1]\n",
    "\n",
    "#     # synchronize using interpolations within overlapping times\n",
    "#     t_min = int(np.max(np.array([t_p[0], t_T[0], t_mp1[0]]))) + 1\n",
    "#     t_max = int(np.min(np.array([t_p[-1], t_T[-1], t_mp1[-1]])))\n",
    "    \n",
    "#     # concatenate data\n",
    "#     t_grav = np.concatenate((t_grav, t_interp))\n",
    "#     p_arr = np.concatenate((p_arr, p_interp))\n",
    "#     T_arr = np.concatenate((T_arr, T_interp))\n",
    "#     br_arr = np.concatenate((br_arr, mp1_interp))\n",
    "#     # indicate that the balance position is mp1 (2)\n",
    "#     bp_arr = np.concatenate((bp_arr, 2*np.ones([len(br_arr)])))\n",
    "    \n",
    "#     # collate data, add a final data point for the zero measurement\n",
    "#     zero_data_pts = zero_data[i, :]\n",
    "#     t_zero = zero_data_pts[0]\n",
    "#     p_zero = zero_data_pts[1]\n",
    "#     T_zero = zero_data_pts[2]\n",
    "#     zero = zero_data_pts[3]\n",
    "#     # assume that the conditions were the same as at the end for the zero point\n",
    "#     t_grav = np.concatenate((t_grav, np.array([t_zero])))\n",
    "#     p_arr = np.concatenate((p_arr, np.array([p_zero])))\n",
    "#     T_arr = np.concatenate((T_arr, np.array([T_zero])))\n",
    "#     br_arr = np.concatenate((br_arr, np.array([zero])))\n",
    "#     # indicate that for the zero measurement, the balance point is 1\n",
    "#     bp_arr = np.concatenate((bp_arr, np.array([1])))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_mp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
